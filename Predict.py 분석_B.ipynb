{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coupled-princeton",
   "metadata": {},
   "source": [
    "# Generating Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This module generates notes for a midi file using the\n",
    "    trained neural network \"\"\"\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import instrument, note, stream, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 신경망을 사용하여 음악을 생성하려면 이전과 같은 상태로 만들어야 합니다\n",
    "# 간단하게 하기 위해 학습 섹션의 코드(chord)를 재사용하여 데이터를 준비하고 전과 동일한 방식으로 네트워크 모델을 설정합니다.\n",
    "\n",
    "\n",
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights('weights.hdf5')\n",
    "    # 각각의 뉴런(노드)의 가중치를 로드합니다.\n",
    "    # 파일에 저장한 학습 결과를 가져오는 것과 같습니다!\n",
    "    \n",
    "    # instead of training the network we load the weights that we saved during the training section into the model.\n",
    "    # 네트워크를 교육하는 대신 학습 섹션에서 저장한 가중치를 모델에 로드합니다.\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-lawyer",
   "metadata": {},
   "source": [
    "# Generating Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 학습된 모델을 사용하여 노트 생성을 시작할 수 있습니다.\n",
    "# 우리가 매번 다른 시퀀스를 입력으로 준다면, 아무것도 하지 않고도 매번 다른 결과를 얻을 수 있습니다. \n",
    "# 매번 다른 시퀀스를 입력하기 위해서는 랜덤 함수를 이용하면 됩니다!\n",
    "\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    # 입력 시퀀스를 랜덤하게 주는 부분.\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "    \n",
    "    # 네트워크 출력을 디코딩하는 매핑 기능도 생성해야 합니다.\n",
    "    # 입력은 categorical 한 것을 숫자로 바꾸었지만 이번엔 반대로 숫자에서 categorical 데이터(정수에서 노트까지)로 매핑합니다.\n",
    "    # 숫자를 노트로 매핑하는 사전을 생성합니다.\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    # 500 개의 노트를 만들어줍니다.\n",
    "    for note_index in range(500):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "# 생성하려는 각 노트에 대해 네트워크에 시퀀스를 제출해야 합니다. \n",
    "# 우리가 입력한 첫 번째 시퀀스는 시작 인덱스에 있는 노트 입니다. \n",
    "# 우리는 다음 출력 시퀀스를 얻기 위해서, 출력된 시퀀스에서 입력으로 사용된 부분을 제거하고 그것을 입력 시퀀스로 씁니다.\n",
    "\n",
    "\n",
    "       # 네트워크 출력에서 가장 가능성이 높은 예측값을 결정하기 위해 가장 높은 확률의 인덱스를 추출합니다.    \n",
    "    # 입력 값에 대해 다음 노트를 예측합니다.\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = numpy.argmax(prediction)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # 결과값은 숫자가 아닌 노트여야 하므로, 미리 만들어놓은 사전에 숫자를 넣어서 맵핑시킵니다.\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)    #  리스트에 모든 출력을 수집합니다.\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "# 이제 리스트에 인코딩된 모든 노트와 코드(chord) 표시가 있으므로 노트의 디코딩을 시작하고 노트와 코드(chord) 개체의 리스트 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "   \n",
    " #먼저 디코딩 중인 출력이 노트인지 또는 코드(chord)인지 확인\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    # 모델에 의해 예측된 값을 바탕으로 노트와 코드(chord) 객체를 만듭니다.\n",
    "    for pattern in prediction_output:  \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():       # 패턴(출력값)이 코드(chord) 일 때\n",
    "            notes_in_chord = pattern.split('.')         # 문자열을 여러 노트로 분할해야 합니다.\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:         # 그런 다음 각 노트의 문자열 표현을 반복하여 각 노트에 대한 노트 개체를 만듭니다. \n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)            # 그러면 각 노트를 포함하는 코드(chord) 개체를 만들 수 있습니다.\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:      # 패턴이(출력값이) 노트일 때\n",
    "            new_note = note.Note(pattern)           # 패턴이 노트 인 경우 패턴에 포함된 계이름을 표현하는 문자열 표현을 사용하여 노트 개체를 만듭니다.\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "            \n",
    "        # 각 반복마다 오프셋을 0.5 씩 증가시켜 줍니다.\n",
    "        # 그렇지 않으면 같은 오프셋에 음이 쌓이게 됩니다.    \n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "        \n",
    "        \n",
    "        \n",
    "# 이제 네트워크에서 생성된 노트 및 코드(chord) 리스트를 매개 변수로 사용하여 Music21 Stream 객체를 만들 것입니다.\n",
    "# 진짜 음악을 만드는 부분입니다. \n",
    "# 마지막으로 네트워크에서 생성된 음악을 저장할 MIDI 파일을 만들기 위해 Music21 툴킷의 쓰기 기능을 사용하여 스트림을 파일에 씁니다.\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
