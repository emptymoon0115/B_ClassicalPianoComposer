{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This module prepares midi file data and feeds it to the neural\n",
    "    network for training \"\"\"\n",
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-aircraft",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "\n",
    "* music21 라이브러리 함수 이해\n",
    "\n",
    " * music21.converter : 다양한 음악 파일 포맷으로부터 음악을 로드하는 툴을 가지고 있습니다.\n",
    " * music21.converter.parse() : 파일의 아이템을 파싱하고 스트림에 넣어줍니다.\n",
    " * instrument.partitionByInstrument() : 단일 스트림, 스코어, 멀티 파트 구조인 경우에 각각의 악기별로 파티션을 나누고 다른 파트들을 하나로 합쳐줍니다.\n",
    " * Stream.recurse : 스트림안에 존재하는 Music21 객체가 가지고 있는 값들의 리스트를 반복(iterate)할 수 있는 iterator 를 리턴해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import glob  # python을 사용하여 디렉토리 안의 특정 확장자 또는 모든 파일을 찾을 수 있습니다.\n",
    "\n",
    "\n",
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)    # coverter : 다양한 음악파일 포맷으로 음악을 로드,   .parse : file의 item을 parsing하고, stream에 넣어줌\n",
    "        \n",
    "                                        # 각 파일을 Music21 스트림 개체로 로드! 스트림 개체를 사용하면 파일에 있는 모든 노트와 코드(chord) 목록이 나옵니다.\n",
    "                                        # 파싱((syntactic) parsing)은 일련의 문자열을 의미있는 토큰(token)으로 분해하고 이들로 이루어진 파스 트리(parse tree)를 만드는 과정을 말한다.\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        # Music21 라이브러리\n",
    "        \n",
    "        try: # file has instrument parts  \n",
    "            s2 = instrument.partitionByInstrument(midi)    #  단일 스트림, 스코어, 멀티 파트 구조인 경우에 각각의 악기별로 파티션을 나누고 다른 파트들을 하나로 합쳐줍니다.\n",
    "            notes_to_parse = s2.parts[0].recurse()    \n",
    "        except: # file has notes in a flat structure   \n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):   # instance가 특정 클래스/데이터 타입과 일치할 경우에는 True를 아닌 경우에는 False를 return해줍니다. \n",
    "                notes.append(str(element.pitch))  # 모든 note object의 pitch(계이름)을 string notaion으로 추가\n",
    "            elif isinstance(element, chord.Chord):   \n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))   # 우리는 각 음을 점으로 나누어서 현 안에 있는 모든 음들의 id를 하나의 문자열로 인코딩함으로써 모든 화음을 추가\n",
    "                # 이러한 인코딩을 통해 네트워크에 의해 생성된 출력을 올바른 노트와 코드(chord)로 쉽게 디코딩할 수 있습니다.\n",
    "                # 이제 모든 노트와 코드(chord)를 순차적 목록에 넣었다   ------> 네트워크의 입력으로 사용될 시퀀스를 만들 수 있습니다.\n",
    "                \n",
    "                \n",
    "                                                   # pickle 모듈을 활용하여 데이터 입력 및 로드\n",
    "    with open('data/notes', 'wb') as filepath:     #  pickle로 데이터를 저장하거나 불러올때는 파일을 바이트형식으로 읽거나 써야한다. (wb, rb)\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-coalition",
   "metadata": {},
   "source": [
    "# Create the sequences that will serve as the input of our network\n",
    "* 네트워크의 입력으로 사용될 시퀀스를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100     # put the length of each sequence to be 100 notes/chords\n",
    "                              # 네트워크에서 다음 노트를 예측하기 위해서 도움이 되는 이전 100개의 노트를 사용한다\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))     # 모든 계이름의 이름을 pitchnames 변수에 저장\n",
    "                                                         # set 으로 중복을 피하고, sorted 함수로 정렬함\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))    # 각 계이름(문자열)을 숫자로 바꾸는 dictionary(사전)을 만든다 -> 숫자기반데이터를 신경망이 더 잘 학습\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs      # 입력 시퀀스를 만든다\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers                # 데이터 입력 형태를 LSTM 레이어에 알맞게 변경함\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input   # 입력값을 normalizing(정규화)\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    #네트워크 데이터 준비의 마지막 단계는 입력을 정규화하고 출력을 원-핫 인코딩하는 것입니다.\n",
    "\n",
    "\n",
    "    return (network_input, network_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-moses",
   "metadata": {},
   "source": [
    "# Model (모델) architecture 설계\n",
    "\n",
    "* 모델은 4가지 유형의 레이어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),     #  input_shape 매개변수를 사용하는 목적은 모델을 학습하기 위해서 쓸 데이터의 형태를 네트워크에 알리는 것입니다.\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True                     # return_sequences: 불리언. 아웃풋 시퀀스의 마지막 아웃풋을 반환할지, 혹은 시퀀스 전체를 반환할지 여부.\n",
    "    ))                                            # return_sequences가 True이므로 첫번째 출력값은 모든 시점의 은닉 상태가 출력됩니다.\n",
    "                                                  # recurrent_dropout: 0과 1사이 부동소수점. 순환 상태의 선형적 변형을 실행하는데 드롭시킬(고려하지 않을) 유닛의 비율.\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))      # LSTM 레이어 는 어떤 시퀀스를 입력으로 넣었을 때 출력으로 또 다른 시퀀스 또는 행렬을 주는 순환신경망입니다\n",
    "    model.add(BatchNorm())    # 케라스에서 배치 정규화는 하나의 레이어(BatchNormalization())처럼 작동하며, 보통 Dense 혹은 Convolution 레이어와 활성함수(Activation) 레이어 사이에 들어간다.\n",
    "    model.add(Dropout(0.3))   # Dropout 레이어 는무작위로 학습을 쓸 뉴런을 정해서 학습을 진행하는 것입니다. mini-batch 마다 랜덤하게 되는 뉴런이 달라지기 때문에 다양한 모델을 쓰는듯한 효과를 냅니다.\n",
    "    model.add(Dense(256))    # Dense 레이어 또는 Fully connected 레이어는 이전 레이어의 모든 뉴런과 결합된 형태의 레이어\n",
    "    model.add(Activation('relu'))  # Activation 레이어는 신경망이 노드의 출력을 계산하는 데 사용할 활성화 기능을 결정합니다 # (relu) rectifier 함수, 은닉층에 주로 쓰입니다.\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))  # ‘softmax’ : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다.\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')   # 반복에 대한 손실을 계산하기 위해, 우리는 categorical cross entropy(범주형 크로스 엔트로피)를 사용\n",
    "                                                                          # 범주형 크로스 엔트로피를 사용하는 이유는 각 출력은 단 한 개의 클래스에만 속해야하고 우리는 두 개 이상의 클래스를 가지고 있기 때문\n",
    "                                                                          # 네트워크를 최적화하기 위해 RMSprop optimizer를 사용할 것입니다. \n",
    "                                                                          # RMSprop optimizer는 일반적으로 순환신경망에 매우 적합합니다. \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 각 LSTM, Dense 및 Activation 레이어에 대해 첫 번째 매개변수는 레이어가 가져야 하는 노드 수입니다. \n",
    "    # Dropout 레이어의 경우 첫 번째 매개변수는 교육 중에 삭제해야 하는 입력 단위의 비율*입니다. 전체의 노드(위에서 설명한 무작위로 정할 뉴런)를 결정하는 비율입니다.\n",
    "\n",
    "    # 마지막 레이어은 항상 시스템의 서로 다른 출력 수와 동일한 수의 노드를 포함해야 합니다. 이는 네트워크 출력이 우리 클래스와 직접 연결되도록 보장합니다.\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-bernard",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # 우리가 열심히 학습한 것을 잃지 않고도 언제든 훈련을 중단할 수 있도록 우리는 모델 체크포인트를 사용할 것입니다. \n",
    "    # 모델 체크포인트는 매 에폭마다 네트워크 노드의 가중치를 파일에 저장할 수 있는 방법을 제공합니다.\n",
    "    # 이것은 우리가 가중치를 잃어 버릴 걱정 없이 손실 값에 만족하면 신경망을 작동시키는 것을 멈출 수 있게 해줍니다.\n",
    "    \n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    \n",
    "\n",
    "    model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)\n",
    "    \n",
    "   # Keras의 model.fit() 함수는 신경망을 학습하는 데 사용됩니다. model.fit() 함수의 첫 번째 파라미터는 앞에서 준비한 입력 시퀀스 목록이고 두 번째 파라미터는 각 출력의 목록입니다. \n",
    "   # 64개의 샘플을 포함하는 네트워크를 통해 전파되는 각 배치에 대해 200 에폭(반복, epoch) 동안 네트워크를 학습할 것입니다.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-mechanics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
